{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHg6i-MrwyWB"
   },
   "source": [
    "## MA 598 Programming Assignment 2:  Due Monday, February 25, 8pm.\n",
    "\n",
    "### Model 1/2\n",
    "Team member names:  Max Ruby, Carlos Salinas\n",
    "\n",
    "In this assignment we use a GRU together with\n",
    "\n",
    "* *Recurrent dropout*, a specific, built-in way to use dropout to fight overfitting in recurrent layers.\n",
    "\n",
    "**Model 1: **  Modify the model described in Chollet, Section 6.3.6 (GRU plus reccurent dropout) as follows: \n",
    "\n",
    "- use a skip connection that adds the baseline prediction of the same temperature 24 hours ago to the output of the GRU, \n",
    "- use only 16 nodes in the GRU instead of 32, and \n",
    "- use a lookback of 432 (3 days).\n",
    "\n",
    "**Model 2:** Extend Model 1 by encoding the date using 2 floating point numbers of the form (cos 2 π t/365, sin 2 π t/365), where t is the number of days from January 1. Likewise, encode the time of day using a similar format.  Include these values as input to the GRU + skip connection from Model 1. \n",
    "\n",
    "\n",
    "### To do:  \n",
    "1. Specify the model number above and indicate the team member names.\n",
    "- Specify your model structure below. \n",
    "- Restart kernel and run all.  \n",
    "- Answer the questions in the next text box - in this assignment for Model 2 only.\n",
    "- Print to pdf.\n",
    "- Combine the pdfs for the 3 models into a single pdf.\n",
    "- Submit on gradescope (indicate the start of each model and your team members on gradescope).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUqHpRkBS5nb"
   },
   "source": [
    "### Questions (Model 2 only):  \n",
    "Give brief (one or two sentence) answers to the questions below.\n",
    "\n",
    "**Q1:** What other data preprocessing could you do that might improve accuracy? \n",
    "\n",
    "**Answer: **\n",
    "\n",
    "**Q2: ** Why do you think that dropout didn't really improve the best test performance in the comparison in the original code from Section 6.3.6?  \n",
    "\n",
    "**Answer: **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1550625459093,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "p8r1E-ZWgoPm",
    "outputId": "8c8cfcfb-ea1e-499a-cda1-cdcf0aa82810"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVNXhrapgoP0"
   },
   "source": [
    "## Recurrent neural networks for weather prediction\n",
    "\n",
    "This notebook adapts the code samples found in Chapter 6, Section 3 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lpEeW_bgoP2"
   },
   "source": [
    "## A temperature forecasting problem\n",
    "\n",
    "This model uses weather \n",
    "timeseries dataset recorded at the Weather Station at the Max-Planck-Institute for Biogeochemistry in Jena, Germany: http://www.bgc-jena.mpg.de/wetter/.\n",
    "\n",
    "In this dataset, fourteen different quantities (such air temperature, atmospheric pressure, humidity, wind direction, etc.) are recorded \n",
    "every ten minutes, over several years. The original data goes back to 2003, but we limit ourselves to data from 2009-2016. This dataset is \n",
    "perfect for learning to work with numerical timeseries. We will use it to build a model that takes as input some data from the recent past (a \n",
    "few days worth of data points) and predicts the air temperature 24 hours in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7A7JSD2tgoP4"
   },
   "source": [
    "First get access to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32445,
     "status": "ok",
     "timestamp": 1550625489865,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "R6b8z4uwgoP5",
    "outputId": "c180f2d1-293f-4650-f92a-1e11a49cd6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "420551\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# data_dir = '/content/gdrive/My Drive/Datasets'\n",
    "data_dir = os.getcwd()\n",
    "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1550633588023,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "gd8Mo15wFo1P",
    "outputId": "75205599-1ad7-45ec-9eb2-195ed33dde31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.01.2009 00:10:00,996.52,-8.02,265.40,-8.90,93.30,3.33,3.11,0.22,1.94,3.12,1307.75,1.03,1.75,152.30\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5jLNcUGgoP_"
   },
   "source": [
    "Convert all of these 420,551 lines of data into a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjGJdAw7goQB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1550634742544,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "b81QVldCF0jz",
    "outputId": "0fe4b364-e948-4960-d812-7985559400b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.96520e+02 -8.02000e+00  2.65400e+02 -8.90000e+00  9.33000e+01\n",
      "  3.33000e+00  3.11000e+00  2.20000e-01  1.94000e+00  3.12000e+00\n",
      "  1.30775e+03  1.03000e+00  1.75000e+00  1.52300e+02]\n"
     ]
    }
   ],
   "source": [
    "print(float_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97qHRCELgoQV"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "\n",
    "The exact formulation of our problem will be the following: given data going as far back as `lookback` timesteps (a timestep is 10 minutes) \n",
    "and sampled every `steps` timesteps, can we predict the temperature in `delay` timesteps?\n",
    "\n",
    "We preprocess the data by subtracting the mean of each timeseries and dividing by the standard deviation. We plan on using the first \n",
    "200,000 timesteps as training data, so we compute the mean and standard deviation only on this fraction of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_k5_M3cOgoQW"
   },
   "outputs": [],
   "source": [
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3r_D2SjgoQa"
   },
   "source": [
    "\n",
    "Now here is the data generator that we will use. It yields a tuple `(samples, targets)` where `samples` is one batch of input data and \n",
    "`targets` is the corresponding array of target temperatures. It takes the following arguments:\n",
    "\n",
    "* `data`: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "* `lookback`: How many timesteps back should our input data go.\n",
    "* `delay`: How many timesteps in the future should our target be.\n",
    "* `min_index` and `max_index`: Indices in the `data` array that delimit which timesteps to draw from. This is useful for keeping a segment \n",
    "of the data for validation and another one for testing.\n",
    "* `shuffle`: Whether to shuffle our samples or draw them in chronological order.\n",
    "* `batch_size`: The number of samples per batch.\n",
    "* `step`: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxUhBRARgoQc"
   },
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eu5fxIqlgoQm"
   },
   "source": [
    "\n",
    "Now let's use our abstract generator function to instantiate three generators, one for training, one for validation and one for testing. \n",
    "Each will look at different temporal segments of the original data: the training generator looks at the first 200,000 timesteps, the \n",
    "validation generator looks at the following 100,000, and the test generator looks at the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kKT16HrgoQm"
   },
   "outputs": [],
   "source": [
    "lookback = 432\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# This is how many steps to draw from `val_gen`\n",
    "# in order to see the whole validation set:\n",
    "val_steps = (300000 - 200001 - lookback) // batch_size\n",
    "\n",
    "# This is how many steps to draw from `test_gen`\n",
    "# in order to see the whole test set:\n",
    "test_steps = (len(float_data) - 300001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APgzTXL-goRK"
   },
   "source": [
    "## A recurrent model\n",
    "\n",
    "\n",
    "Instead of the `LSTM` layer introduced in the previous section, we will use the `GRU` layer, developed by Cho et al. in 2014. `GRU` layers \n",
    "(which stands for \"gated recurrent unit\") work by leveraging the same principle as LSTM, but they are somewhat streamlined and thus cheaper \n",
    "to run, albeit they may not have quite as much representational power as LSTM. This trade-off between computational expensiveness and \n",
    "representational power is seen everywhere in machine learning.\n",
    "\n",
    "The model below uses recurrent dropout to help prevent overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VKAkSyggoRZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 40s 81ms/step - loss: 0.4942 - val_loss: 0.4580\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.4707 - val_loss: 0.4532\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.4570 - val_loss: 0.4428\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.4440 - val_loss: 0.4129\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 0.4089 - val_loss: 0.3544\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 0.3631 - val_loss: 0.3104\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 0.3403 - val_loss: 0.2931\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 39s 79ms/step - loss: 0.3240 - val_loss: 0.2868\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.3159 - val_loss: 0.2821\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.3113 - val_loss: 0.2848\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.3064 - val_loss: 0.2806\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.3033 - val_loss: 0.2801\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.2979 - val_loss: 0.2781\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.3005 - val_loss: 0.2754\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.2987 - val_loss: 0.2738\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.2962 - val_loss: 0.2767\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.2962 - val_loss: 0.2737\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.2952 - val_loss: 0.2753\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.2950 - val_loss: 0.2743\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2941 - val_loss: 0.2719\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2926 - val_loss: 0.2710\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2915 - val_loss: 0.2735\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2912 - val_loss: 0.2697\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2910 - val_loss: 0.2701\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2910 - val_loss: 0.2715\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 43s 85ms/step - loss: 0.2930 - val_loss: 0.2706\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 42s 83ms/step - loss: 0.2901 - val_loss: 0.2713\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2899 - val_loss: 0.2710\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 43s 85ms/step - loss: 0.2902 - val_loss: 0.2695\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2918 - val_loss: 0.2680\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2899 - val_loss: 0.2726\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.2896 - val_loss: 0.2693\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2889 - val_loss: 0.2683\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2888 - val_loss: 0.2691\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2886 - val_loss: 0.2739\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2877 - val_loss: 0.2671\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 43s 85ms/step - loss: 0.2880 - val_loss: 0.2701\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 42s 85ms/step - loss: 0.2875 - val_loss: 0.2690\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 39s 77ms/step - loss: 0.2873 - val_loss: 0.2700\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 43s 85ms/step - loss: 0.2875 - val_loss: 0.2695\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, Input, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "## Original model\n",
    "clicks = int(lookback/step)\n",
    "a = 2 \n",
    "inputs = Input(shape=(clicks,float_data.shape[-1]))\n",
    "x = layers.GRU(16,dropout=0.2,recurrent_dropout=0.2,input_shape=(clicks,float_data.shape[-1]))(inputs)\n",
    "x = layers.Dense(1)(x)\n",
    "#This is a giant mess of things that allows us to pick the temperature value from 1 day ago out\n",
    "temp = layers.Flatten()(inputs)\n",
    "temp = layers.Reshape((clicks*float_data.shape[-1],1),input_shape=(clicks*float_data.shape[-1],))(temp)\n",
    "temp = layers.Cropping1D(cropping=(a,clicks*float_data.shape[-1]-a-1))(temp)\n",
    "temp = layers.Flatten()(temp)\n",
    "#Skip connection goes here\n",
    "x = layers.add([x,temp])\n",
    "\n",
    "model=Model(inputs=inputs,outputs=x)\n",
    "model.compile(optimizer=RMSprop(),loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocgxmgoKgoRh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment 2 template.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
