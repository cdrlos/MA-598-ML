{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 2 template.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"wHg6i-MrwyWB","colab_type":"text"},"cell_type":"markdown","source":["## MA 598 Programming Assignment 2:  Due Monday, February 25, 8pm.\n","\n","### Model 1/2\n","Team member names:  \n","\n","In this assignment we use a GRU together with\n","\n","* *Recurrent dropout*, a specific, built-in way to use dropout to fight overfitting in recurrent layers.\n","\n","**Model 1: **  Modify the model described in Chollet, Section 6.3.6 (GRU plus reccurent dropout) as follows: \n","\n","- use a skip connection that adds the baseline prediction of the same temperature 24 hours ago to the output of the GRU, \n","- use only 16 nodes in the GRU instead of 32, and \n","- use a lookback of 432 (3 days).\n","\n","**Model 2:** Extend Model 1 by encoding the date using 2 floating point numbers of the form (cos 2 π t/365, sin 2 π t/365), where t is the number of days from January 1. Likewise, encode the time of day using a similar format.  Include these values as input to the GRU + skip connection from Model 1. \n","\n","\n","### To do:  \n","1. Specify the model number above and indicate the team member names.\n","- Specify your model structure below. \n","- Restart kernel and run all.  \n","- Answer the questions in the next text box - in this assignment for Model 2 only.\n","- Print to pdf.\n","- Combine the pdfs for the 3 models into a single pdf.\n","- Submit on gradescope (indicate the start of each model and your team members on gradescope).  "]},{"metadata":{"id":"UUqHpRkBS5nb","colab_type":"text"},"cell_type":"markdown","source":["### Questions (Model 2 only):  \n","Give brief (one or two sentence) answers to the questions below.\n","\n","**Q1:** What other data preprocessing could you do that might improve accuracy? \n","\n","**Answer: **\n","\n","**Q2: ** Why do you think that dropout didn't really improve the best test performance in the comparison in the original code from Section 6.3.6?  \n","\n","**Answer: **\n"]},{"metadata":{"id":"p8r1E-ZWgoPm","colab_type":"code","outputId":"8c8cfcfb-ea1e-499a-cda1-cdcf0aa82810","executionInfo":{"status":"ok","timestamp":1550625459093,"user_tz":300,"elapsed":1727,"user":{"displayName":"Gregery T Buzzard","photoUrl":"https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg","userId":"14140499485883029775"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["import keras\n","keras.__version__"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"tVNXhrapgoP0","colab_type":"text"},"cell_type":"markdown","source":["## Recurrent neural networks for weather prediction\n","\n","This notebook adapts the code samples found in Chapter 6, Section 3 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n","\n","---\n","\n"]},{"metadata":{"id":"2lpEeW_bgoP2","colab_type":"text"},"cell_type":"markdown","source":["## A temperature forecasting problem\n","\n","This model uses weather \n","timeseries dataset recorded at the Weather Station at the Max-Planck-Institute for Biogeochemistry in Jena, Germany: http://www.bgc-jena.mpg.de/wetter/.\n","\n","In this dataset, fourteen different quantities (such air temperature, atmospheric pressure, humidity, wind direction, etc.) are recorded \n","every ten minutes, over several years. The original data goes back to 2003, but we limit ourselves to data from 2009-2016. This dataset is \n","perfect for learning to work with numerical timeseries. We will use it to build a model that takes as input some data from the recent past (a \n","few days worth of data points) and predicts the air temperature 24 hours in the future."]},{"metadata":{"id":"7A7JSD2tgoP4","colab_type":"text"},"cell_type":"markdown","source":["First get access to the data:"]},{"metadata":{"id":"g2dXPhm7sMxz","colab_type":"code","outputId":"2675679f-527e-4178-c059-453ca04b644c","executionInfo":{"status":"ok","timestamp":1550625488461,"user_tz":300,"elapsed":31070,"user":{"displayName":"Gregery T Buzzard","photoUrl":"https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg","userId":"14140499485883029775"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"CRGW3KyAR63r","colab_type":"text"},"cell_type":"markdown","source":["Look at the header and a few lines to understand the data better.  "]},{"metadata":{"id":"R6b8z4uwgoP5","colab_type":"code","outputId":"c180f2d1-293f-4650-f92a-1e11a49cd6da","executionInfo":{"status":"ok","timestamp":1550625489865,"user_tz":300,"elapsed":32445,"user":{"displayName":"Gregery T Buzzard","photoUrl":"https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg","userId":"14140499485883029775"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"cell_type":"code","source":["import os\n","\n","data_dir = '/content/gdrive/My Drive/Datasets'\n","fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n","\n","f = open(fname)\n","data = f.read()\n","f.close()\n","\n","lines = data.split('\\n')\n","header = lines[0].split(',')\n","lines = lines[1:]\n","\n","print(header)\n","print(len(lines))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n","420551\n"],"name":"stdout"}]},{"metadata":{"id":"gd8Mo15wFo1P","colab_type":"code","outputId":"75205599-1ad7-45ec-9eb2-195ed33dde31","executionInfo":{"status":"ok","timestamp":1550633588023,"user_tz":300,"elapsed":450,"user":{"displayName":"Gregery T Buzzard","photoUrl":"https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg","userId":"14140499485883029775"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["print(lines[1000:1003])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['07.01.2009 22:50:00,997.79,-10.79,262.54,-11.84,91.90,2.68,2.46,0.22,1.53,2.47,1323.57,0.24,0.63,139.40', '07.01.2009 23:00:00,997.88,-10.68,262.64,-11.74,91.80,2.70,2.48,0.22,1.55,2.48,1323.13,0.10,0.50,184.20', '07.01.2009 23:10:00,998.05,-10.99,262.32,-12.14,91.10,2.63,2.40,0.23,1.50,2.40,1324.97,0.20,0.63,146.60']\n"],"name":"stdout"}]},{"metadata":{"id":"L5jLNcUGgoP_","colab_type":"text"},"cell_type":"markdown","source":["Convert all of these 420,551 lines of data into a Numpy array:"]},{"metadata":{"id":"hjGJdAw7goQB","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","float_data = np.zeros((len(lines), len(header) - 1))\n","for i, line in enumerate(lines):\n","    values = [float(x) for x in line.split(',')[1:]]\n","    float_data[i, :] = values\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"b81QVldCF0jz","colab_type":"code","outputId":"0fe4b364-e948-4960-d812-7985559400b5","executionInfo":{"status":"ok","timestamp":1550634742544,"user_tz":300,"elapsed":591,"user":{"displayName":"Gregery T Buzzard","photoUrl":"https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg","userId":"14140499485883029775"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"cell_type":"code","source":["print(float_data[1000:1003])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[ 9.97790e+02 -1.07900e+01  2.62540e+02 -1.18400e+01  9.19000e+01\n","   2.68000e+00  2.46000e+00  2.20000e-01  1.53000e+00  2.47000e+00\n","   1.32357e+03  2.40000e-01  6.30000e-01  1.39400e+02]\n"," [ 9.97880e+02 -1.06800e+01  2.62640e+02 -1.17400e+01  9.18000e+01\n","   2.70000e+00  2.48000e+00  2.20000e-01  1.55000e+00  2.48000e+00\n","   1.32313e+03  1.00000e-01  5.00000e-01  1.84200e+02]\n"," [ 9.98050e+02 -1.09900e+01  2.62320e+02 -1.21400e+01  9.11000e+01\n","   2.63000e+00  2.40000e+00  2.30000e-01  1.50000e+00  2.40000e+00\n","   1.32497e+03  2.00000e-01  6.30000e-01  1.46600e+02]]\n","[[0.01917691 0.99981611 0.81422261 0.58055279]\n"," [0.01917691 0.99981611 0.81823456 0.57488451]\n"," [0.01917691 0.99981611 0.82220706 0.56918851]]\n"],"name":"stdout"}]},{"metadata":{"id":"97qHRCELgoQV","colab_type":"text"},"cell_type":"markdown","source":["## Preparing the data\n","\n","\n","The exact formulation of our problem will be the following: given data going as far back as `lookback` timesteps (a timestep is 10 minutes) \n","and sampled every `steps` timesteps, can we predict the temperature in `delay` timesteps?\n","\n","We preprocess the data by subtracting the mean of each timeseries and dividing by the standard deviation. We plan on using the first \n","200,000 timesteps as training data, so we compute the mean and standard deviation only on this fraction of the data:"]},{"metadata":{"id":"_k5_M3cOgoQW","colab_type":"code","colab":{}},"cell_type":"code","source":["mean = float_data[:200000].mean(axis=0)\n","float_data -= mean\n","std = float_data[:200000].std(axis=0)\n","float_data /= std"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U3r_D2SjgoQa","colab_type":"text"},"cell_type":"markdown","source":["\n","Now here is the data generator that we will use. It yields a tuple `(samples, targets)` where `samples` is one batch of input data and \n","`targets` is the corresponding array of target temperatures. It takes the following arguments:\n","\n","* `data`: The original array of floating point data, which we just normalized in the code snippet above.\n","* `lookback`: How many timesteps back should our input data go.\n","* `delay`: How many timesteps in the future should our target be.\n","* `min_index` and `max_index`: Indices in the `data` array that delimit which timesteps to draw from. This is useful for keeping a segment \n","of the data for validation and another one for testing.\n","* `shuffle`: Whether to shuffle our samples or draw them in chronological order.\n","* `batch_size`: The number of samples per batch.\n","* `step`: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."]},{"metadata":{"id":"yxUhBRARgoQc","colab_type":"code","colab":{}},"cell_type":"code","source":["def generator(data, lookback, delay, min_index, max_index,\n","              shuffle=False, batch_size=128, step=6):\n","    if max_index is None:\n","        max_index = len(data) - delay - 1\n","    i = min_index + lookback\n","    while 1:\n","        if shuffle:\n","            rows = np.random.randint(\n","                min_index + lookback, max_index, size=batch_size)\n","        else:\n","            if i + batch_size >= max_index:\n","                i = min_index + lookback\n","            rows = np.arange(i, min(i + batch_size, max_index))\n","            i += len(rows)\n","\n","        samples = np.zeros((len(rows),\n","                           lookback // step,\n","                           data.shape[-1]))\n","        targets = np.zeros((len(rows),))\n","        for j, row in enumerate(rows):\n","            indices = range(rows[j] - lookback, rows[j], step)\n","            samples[j] = data[indices]\n","            targets[j] = data[rows[j] + delay][1]\n","        yield samples, targets"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eu5fxIqlgoQm","colab_type":"text"},"cell_type":"markdown","source":["\n","Now let's use our abstract generator function to instantiate three generators, one for training, one for validation and one for testing. \n","Each will look at different temporal segments of the original data: the training generator looks at the first 200,000 timesteps, the \n","validation generator looks at the following 100,000, and the test generator looks at the remainder."]},{"metadata":{"id":"5kKT16HrgoQm","colab_type":"code","colab":{}},"cell_type":"code","source":["lookback = 720\n","step = 6\n","delay = 144\n","batch_size = 128\n","\n","train_gen = generator(float_data,\n","                      lookback=lookback,\n","                      delay=delay,\n","                      min_index=0,\n","                      max_index=200000,\n","                      shuffle=True,\n","                      step=step, \n","                      batch_size=batch_size)\n","val_gen = generator(float_data,\n","                    lookback=lookback,\n","                    delay=delay,\n","                    min_index=200001,\n","                    max_index=300000,\n","                    step=step,\n","                    batch_size=batch_size)\n","test_gen = generator(float_data,\n","                     lookback=lookback,\n","                     delay=delay,\n","                     min_index=300001,\n","                     max_index=None,\n","                     step=step,\n","                     batch_size=batch_size)\n","\n","# This is how many steps to draw from `val_gen`\n","# in order to see the whole validation set:\n","val_steps = (300000 - 200001 - lookback) // batch_size\n","\n","# This is how many steps to draw from `test_gen`\n","# in order to see the whole test set:\n","test_steps = (len(float_data) - 300001 - lookback) // batch_size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"APgzTXL-goRK","colab_type":"text"},"cell_type":"markdown","source":["## A recurrent model\n","\n","\n","Instead of the `LSTM` layer introduced in the previous section, we will use the `GRU` layer, developed by Cho et al. in 2014. `GRU` layers \n","(which stands for \"gated recurrent unit\") work by leveraging the same principle as LSTM, but they are somewhat streamlined and thus cheaper \n","to run, albeit they may not have quite as much representational power as LSTM. This trade-off between computational expensiveness and \n","representational power is seen everywhere in machine learning.\n","\n","The model below uses recurrent dropout to help prevent overfitting.  "]},{"metadata":{"id":"0VKAkSyggoRZ","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras import layers, Input, Model\n","from keras.optimizers import RMSprop\n","\n","model = Sequential()\n","model.add(layers.GRU(32,\n","                     dropout=0.2,\n","                     recurrent_dropout=0.2,\n","                     input_shape=(None, float_data.shape[-1])))\n","model.add(layers.Dense(1))\n","\n","model.compile(optimizer=RMSprop(), loss='mae')\n","history = model.fit_generator(train_gen,\n","                              steps_per_epoch=500,\n","                              epochs=40,\n","                              validation_data=val_gen,\n","                              validation_steps=val_steps)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ocgxmgoKgoRh","colab_type":"code","colab":{}},"cell_type":"code","source":["loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(loss))\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]}]}