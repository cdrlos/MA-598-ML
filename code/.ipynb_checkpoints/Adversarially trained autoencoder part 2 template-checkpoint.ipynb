{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "5esRoMwG3oW_",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Adversarially trained autoencoder  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "VZqQalQ83oXA",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Part 2:\n",
    "In part 2, we add the adversarial part by coupling  the autoencoder with a discriminator. \n",
    "* A `discriminator` network maps images of shape (32, 32, 3) to a binary score estimating the probability that the image is real.\n",
    "* A `gan` network chains the generator and the discriminator together: `gan(x) = discriminator(autoencoder(x))`. Thus this `gan` network maps \n",
    "latent space vectors to the discriminator's assessment of the realism of these latent vectors as decoded by the generator.\n",
    "\n",
    "We train the autoencoder using a weighted sum of the mse loss and binary cross entropy on the output of the discriminator.\n",
    "\n",
    "To do this, the gan will need to have two outputs and two loss functions that are combined via a weighted sum.  There is documentation about that here:  [multi-input-and-multi-output-models](https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models)\n",
    "\n",
    "In alternation, we train the discriminator using examples of real and fake images along with \"real\"/\"fake\" labels, as we would train any regular image classification model.  This uses binary cross entropy loss. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "UJk6i9Ge3oXC",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## The autoencoder\n",
    "\n",
    "\n",
    "Use the same autoencoder structure from part 1.  Do not use a saved version of that autoencoder - just use the same structure, but start with an untrained model.  One of the points of this assignment is to compare the results of training with mse versus training with mse plus adversarial loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "DGM0UeIFGIVb",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential, Conv2D\n",
    "from keras.layers import Dense, Activation,\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "img_input = keras.Input(shape=(height, width, channels))\n",
    "\n",
    "# Your network here to connect img_input to img_output\n",
    "\n",
    "encoder = Sequential()\n",
    "encoder.add(Conv2D(8,(7,7),input_shape=(height,width,channels)))\n",
    "encoder.add(Conv2D(16,(5,5),input_shape=(32,32,3)))\n",
    "encoder.add(Conv2D(32,(3,3),input_shape=(32,32,3)))\n",
    "encoder.add(Conv2D(128,(3,3),input_shape=(32,32,3)))\n",
    "encoder.add(Dense(input_shape=(18,18,64)))\n",
    "encoder.add(Dense())\n",
    "encoder.add(Dense())\n",
    "\n",
    "# img_output =\n",
    "\n",
    "autoencoder = keras.models.Model(img_input, img_output)\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "uY6biDGR-KGL",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here is some code to load the data and display images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "9nirTlrjtNmc",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Select frog images (class 6)\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "x_test = x_test[y_test.flatten() == 6]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "x_test = x_test.reshape(\n",
    "    (x_test.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# input a tensor of shape (num_images, x_size, y_size, channels)\n",
    "# channels is 1 for greyscale and 3 for color images\n",
    "def show_images(images):\n",
    "  # Display tiled images\n",
    "  n_x = np.int(np.sqrt(images.shape[0]))\n",
    "  n_y = np.int(np.ceil(images.shape[0]/n_x))\n",
    "  tile_x = images.shape[1]\n",
    "  tile_y = images.shape[2]\n",
    "  figure = np.zeros((tile_x * n_x, tile_y * n_y, images.shape[3]))\n",
    "\n",
    "  for i in range(n_x):  \n",
    "    for j in range(n_y):  \n",
    "      cur_ind = i+n_x*j\n",
    "      if (cur_ind >= images.shape[0]):\n",
    "        break\n",
    "      cur_image = images[cur_ind, :,:,:]\n",
    "      figure[i * tile_x: (i + 1) * tile_x,\n",
    "         j * tile_y: (j + 1) * tile_y] = cur_image\n",
    "\n",
    "  plt.figure(figsize=(n_x, n_y))\n",
    "  plt.imshow(np.squeeze(figure))\n",
    "  ax = plt.gca()\n",
    "  ax.grid(b=None)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "dI9h91hK3oXF",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## The discriminator\n",
    "\n",
    "\n",
    "Then, we develop a `discriminator` model, that takes as input a candidate image (real or synthetic) and classifies it into one of two \n",
    "classes, either \"generated image\" or \"real image that comes from the training set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "zPXEEvKM3oXG",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "# Your code here for the discriminator\n",
    "# There is one example of a discriminator in Deep Learning with Python, section 8.5\n",
    "\n",
    "# Your discriminator should end with the final binary classification layer:\n",
    "discriminator_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, discriminator_output)\n",
    "discriminator.summary()\n",
    "\n",
    "# To stabilize training, we use learning rate decay\n",
    "# and gradient clipping (by value) in the optimizer.\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "6JZn-IAW3oXK",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## The adversarial network\n",
    "\n",
    "Finally, we setup an adversarial network (AN) that chains the autoencoder and the discriminator. This will move the autoencoder \n",
    "in a direction that improves its ability to fool the discriminator while still reproducing its input. The AN is meant to be trained with labels that are always \"these are real images\", so the \n",
    "weights of `autoencoder` will be updated to make `discriminator` more likely to predict \"real\" when looking at fake images. Very importantly, we \n",
    "set the discriminator to be frozen during training (non-trainable): its weights will not be updated when training `gan`. If the \n",
    "discriminator weights could be updated during this process, then we would be training the discriminator to always predict \"real\", which is \n",
    "not what we want!  \n",
    "\n",
    "Note: Setting nontrainable weights may give a warning about a mismatch between trainable and nontrainable weights, but you may ignore that.  \n",
    "\n",
    "You will need to set up your model to have a loss function that is a weighted sum of the mse on the autoencoder and the binary cross entropy from the discriminator.   The link in the introduction gives information about how to do that.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "0XP8ph5Y3oXK",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Set discriminator weights to non-trainable\n",
    "# (will only apply to the `gan` model)\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Set up the gan to output both the image and the real/fake value from the discriminator\n",
    "# See https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models\n",
    "gan_input = keras.Input(shape=(height, width, channels,))\n",
    "\n",
    "\n",
    "gan = keras.models.Model(gan_input, # your code here to set up the outputs\n",
    "                        )\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer,\n",
    "            # your code here to set up the loss function\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "eXf3yTEG3oXN",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Training you AN\n",
    "\n",
    "Now we can start training. To recapitulate, this is schematically what the training loop looks like:\n",
    "\n",
    "```\n",
    "for each epoch:\n",
    "    * Draw a batch of training images\n",
    "    * Reconstruct images with `autoencoder` \n",
    "    * Mix the generated images with real ones.\n",
    "    * Train `discriminator` using these mixed images, with corresponding targets, either \"real\" (for the real images) or \"fake\" (for the generated images).\n",
    "    * Draw new random images.\n",
    "    * Train `gan` using these random images, with targets that all say \"these are real images\". This will update the weights of the autoencoder (only, since discriminator is frozen inside `an`) to move them towards getting the discriminator to predict \"these are real images\" for generated images, i.e. this trains the autoencoder to fool the discriminator.\n",
    "```\n",
    "\n",
    "The code below does most of this.  You'll need to set up the training on batches.  You should also find a way to get and plot the validation loss - the loss on the test data.  This is not included below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "ODGq14j03oXO",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128 \n",
    "num_epochs = 100\n",
    "\n",
    "print('Number of epochs = ' + str(num_epochs))\n",
    "\n",
    "adv_loss = np.zeros((num_epochs, 3))\n",
    "val_adv_loss = np.zeros((num_epochs, 3))\n",
    "disc_loss = np.zeros((num_epochs, 1))\n",
    "\n",
    "max_ind = x_train.shape[0]\n",
    "# Start training loop\n",
    "start = 0\n",
    "epoch = 0\n",
    "while epoch < num_epochs:\n",
    "  \n",
    "    if (start == 0):\n",
    "        cur_perm = np.random.permutation(max_ind)\n",
    "      \n",
    "    # Sample random training images\n",
    "    stop = start + batch_size\n",
    "    random_images = x_train[cur_perm[start:stop]]\n",
    "\n",
    "    # Decode them to reconstructed images\n",
    "    generated_images = # Your code here\n",
    "\n",
    "    # Combine them with real images   \n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = np.concatenate([0.95*np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])  # 0=real, 1=fake\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the generator (via the AN model,\n",
    "    # where the discriminator weights are frozen)\n",
    "    a_loss = gan.train_on_batch(  # Add code to include training data that includes both random_images and misleading_targets\n",
    "                                )\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "\n",
    "        # Print metrics\n",
    "        print('discriminator loss at epoch %s: %s' % (epoch, d_loss))\n",
    "        print('adversarial loss at epoch %s: %s' % (epoch, a_loss))\n",
    "        \n",
    "        adv_loss[epoch,:] = a_loss\n",
    "        disc_loss[epoch,:] = d_loss\n",
    "        \n",
    "        # Calculate and save the validation loss (mse on image only)\n",
    "        val_adv_loss[epoch,:] = # Your code here\n",
    "\n",
    "        epoch += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "id": "-jLnnq0N3oXS",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Display a few reconstructed images and the training plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "_KJvX7qA3oXT",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ae_images, discrim = gan.predict(x_train[0:64])\n",
    "show_images(ae_images)\n",
    "show_images(x_train[0:64])\n",
    "\n",
    "loss = adv_loss[:,1]  # Set up so this is mse on the images\n",
    "val_loss = val_adv_loss[:,1]\n",
    "epochs = range(num_epochs)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": null,
   "name": "Adversarially trained autoencoder part 2 template with history.ipynb",
   "provenance": null,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "Adversarially trained autoencoder part 2 template.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
