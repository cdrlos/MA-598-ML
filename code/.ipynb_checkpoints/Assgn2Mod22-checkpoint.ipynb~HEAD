{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHg6i-MrwyWB"
   },
   "source": [
    "## MA 598 Programming Assignment 2:  Due Monday, February 25, 8pm.\n",
    "\n",
    "### Model 1/2\n",
    "Team member names:  Max Ruby, Carlos Salinas\n",
    "\n",
    "In this assignment we use a GRU together with\n",
    "\n",
    "* *Recurrent dropout*, a specific, built-in way to use dropout to fight overfitting in recurrent layers.\n",
    "\n",
    "**Model 1: **  Modify the model described in Chollet, Section 6.3.6 (GRU plus reccurent dropout) as follows: \n",
    "\n",
    "- use a skip connection that adds the baseline prediction of the same temperature 24 hours ago to the output of the GRU, \n",
    "- use only 16 nodes in the GRU instead of 32, and \n",
    "- use a lookback of 432 (3 days).\n",
    "\n",
    "**Model 2:** Extend Model 1 by encoding the date using 2 floating point numbers of the form (cos 2 π t/365, sin 2 π t/365), where t is the number of days from January 1. Likewise, encode the time of day using a similar format.  Include these values as input to the GRU + skip connection from Model 1. \n",
    "\n",
    "\n",
    "### To do:  \n",
    "1. Specify the model number above and indicate the team member names.\n",
    "- Specify your model structure below. \n",
    "- Restart kernel and run all.  \n",
    "- Answer the questions in the next text box - in this assignment for Model 2 only.\n",
    "- Print to pdf.\n",
    "- Combine the pdfs for the 3 models into a single pdf.\n",
    "- Submit on gradescope (indicate the start of each model and your team members on gradescope).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUqHpRkBS5nb"
   },
   "source": [
    "### Questions (Model 2 only):  \n",
    "Give brief (one or two sentence) answers to the questions below.\n",
    "\n",
    "**Q1:** What other data preprocessing could you do that might improve accuracy? \n",
    "\n",
    "**Answer:** Some of the quantities are probably related by some equation; coding this in somehow may be of value.\n",
    "\n",
    "**Q2:** Why do you think that dropout didn't really improve the best test performance in the comparison in the original code from Section 6.3.6?  \n",
    "\n",
    "**Answer:** The dropout is done to make sure our weights aren't \"relying\" on each other too much; because we don't have that many parameters, dropout doesn't seem particularly valuable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1550625459093,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "p8r1E-ZWgoPm",
    "outputId": "8c8cfcfb-ea1e-499a-cda1-cdcf0aa82810"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVNXhrapgoP0"
   },
   "source": [
    "## Recurrent neural networks for weather prediction\n",
    "\n",
    "This notebook adapts the code samples found in Chapter 6, Section 3 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lpEeW_bgoP2"
   },
   "source": [
    "## A temperature forecasting problem\n",
    "\n",
    "This model uses weather \n",
    "timeseries dataset recorded at the Weather Station at the Max-Planck-Institute for Biogeochemistry in Jena, Germany: http://www.bgc-jena.mpg.de/wetter/.\n",
    "\n",
    "In this dataset, fourteen different quantities (such air temperature, atmospheric pressure, humidity, wind direction, etc.) are recorded \n",
    "every ten minutes, over several years. The original data goes back to 2003, but we limit ourselves to data from 2009-2016. This dataset is \n",
    "perfect for learning to work with numerical timeseries. We will use it to build a model that takes as input some data from the recent past (a \n",
    "few days worth of data points) and predicts the air temperature 24 hours in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7A7JSD2tgoP4"
   },
   "source": [
    "First get access to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31070,
     "status": "ok",
     "timestamp": 1550625488461,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "g2dXPhm7sMxz",
    "outputId": "2675679f-527e-4178-c059-453ca04b644c"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRGW3KyAR63r"
   },
   "source": [
    "Look at the header and a few lines to understand the data better.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32445,
     "status": "ok",
     "timestamp": 1550625489865,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "R6b8z4uwgoP5",
    "outputId": "c180f2d1-293f-4650-f92a-1e11a49cd6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "420551\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# data_dir = '/content/gdrive/My Drive/Datasets'\n",
    "data_dir = os.getcwd()\n",
    "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1550633588023,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "gd8Mo15wFo1P",
    "outputId": "75205599-1ad7-45ec-9eb2-195ed33dde31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420551\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5jLNcUGgoP_"
   },
   "source": [
    "Convert all of these 420,551 lines of data into a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjGJdAw7goQB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def date_to_real(date):\n",
    "    \"Convert the dates to the periodic format specified by Model 2. Does not account for leap years.\"\n",
    "    temp = []\n",
    "    days_in_months = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    temp = date.split(\".\")\n",
    "    days = days_in_months[int(temp[1])-1]+int(temp[0])\n",
    "    temp = temp[-1]\n",
    "    temp = temp.split(\" \")\n",
    "    temp = temp[-1]\n",
    "    temp = temp.split(\":\")\n",
    "    seconds = int(temp[0])*3600+int(temp[1])*60+int(temp[2])\n",
    "    return [np.cos(np.pi*days/365),np.sin(np.pi*days/365),np.cos(np.pi*seconds/86400),np.sin(np.pi*seconds/86400)]\n",
    "\n",
    "# float_data = np.zeros((len(lines), len(header) - 1))\n",
    "float_data = np.zeros((len(lines), len(header) + 3))\n",
    "for i, line in enumerate(lines):\n",
    "    date = line.split(',')[0]\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "#     float_data[i, :] = values\n",
    "    float_data[i, 0:4] = date_to_real(date)\n",
    "    float_data[i, 4:] = values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1550634742544,
     "user": {
      "displayName": "Gregery T Buzzard",
      "photoUrl": "https://lh6.googleusercontent.com/-wsbJkMRzkiI/AAAAAAAAAAI/AAAAAAAAADk/SiV0nNoXynw/s64/photo.jpg",
      "userId": "14140499485883029775"
     },
     "user_tz": 300
    },
    "id": "b81QVldCF0jz",
    "outputId": "0fe4b364-e948-4960-d812-7985559400b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.62309077e-01  2.71958158e-01  9.99762027e-01  2.18148850e-02\n",
      "  9.96520000e+02 -8.02000000e+00  2.65400000e+02 -8.90000000e+00\n",
      "  9.33000000e+01  3.33000000e+00  3.11000000e+00  2.20000000e-01\n",
      "  1.94000000e+00  3.12000000e+00  1.30775000e+03  1.03000000e+00\n",
      "  1.75000000e+00  1.52300000e+02]\n"
     ]
    }
   ],
   "source": [
    "print(float_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97qHRCELgoQV"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "\n",
    "The exact formulation of our problem will be the following: given data going as far back as `lookback` timesteps (a timestep is 10 minutes) \n",
    "and sampled every `steps` timesteps, can we predict the temperature in `delay` timesteps?\n",
    "\n",
    "We preprocess the data by subtracting the mean of each timeseries and dividing by the standard deviation. We plan on using the first \n",
    "200,000 timesteps as training data, so we compute the mean and standard deviation only on this fraction of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_k5_M3cOgoQW"
   },
   "outputs": [],
   "source": [
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3r_D2SjgoQa"
   },
   "source": [
    "\n",
    "Now here is the data generator that we will use. It yields a tuple `(samples, targets)` where `samples` is one batch of input data and \n",
    "`targets` is the corresponding array of target temperatures. It takes the following arguments:\n",
    "\n",
    "* `data`: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "* `lookback`: How many timesteps back should our input data go.\n",
    "* `delay`: How many timesteps in the future should our target be.\n",
    "* `min_index` and `max_index`: Indices in the `data` array that delimit which timesteps to draw from. This is useful for keeping a segment \n",
    "of the data for validation and another one for testing.\n",
    "* `shuffle`: Whether to shuffle our samples or draw them in chronological order.\n",
    "* `batch_size`: The number of samples per batch.\n",
    "* `step`: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxUhBRARgoQc"
   },
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eu5fxIqlgoQm"
   },
   "source": [
    "\n",
    "Now let's use our abstract generator function to instantiate three generators, one for training, one for validation and one for testing. \n",
    "Each will look at different temporal segments of the original data: the training generator looks at the first 200,000 timesteps, the \n",
    "validation generator looks at the following 100,000, and the test generator looks at the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kKT16HrgoQm"
   },
   "outputs": [],
   "source": [
    "lookback = 720\n",
    "# lookback = 432\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "# This is how many steps to draw from `val_gen`\n",
    "# in order to see the whole validation set:\n",
    "val_steps = (300000 - 200001 - lookback) // batch_size\n",
    "\n",
    "# This is how many steps to draw from `test_gen`\n",
    "# in order to see the whole test set:\n",
    "test_steps = (len(float_data) - 300001 - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APgzTXL-goRK"
   },
   "source": [
    "## A recurrent model\n",
    "\n",
    "\n",
    "Instead of the `LSTM` layer introduced in the previous section, we will use the `GRU` layer, developed by Cho et al. in 2014. `GRU` layers \n",
    "(which stands for \"gated recurrent unit\") work by leveraging the same principle as LSTM, but they are somewhat streamlined and thus cheaper \n",
    "to run, albeit they may not have quite as much representational power as LSTM. This trade-off between computational expensiveness and \n",
    "representational power is seen everywhere in machine learning.\n",
    "\n",
    "The model below uses recurrent dropout to help prevent overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VKAkSyggoRZ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 0.6585 - val_loss: 0.5432\n",
      "Epoch 2/40\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.5952 - val_loss: 0.5346\n",
      "Epoch 3/40\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.5797 - val_loss: 0.5315\n",
      "Epoch 4/40\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.5648 - val_loss: 0.5300\n",
      "Epoch 5/40\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 0.5459 - val_loss: 0.5149\n",
      "Epoch 6/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.5181 - val_loss: 0.4442\n",
      "Epoch 7/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.4499 - val_loss: 0.3186\n",
      "Epoch 8/40\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.3810 - val_loss: 0.2441\n",
      "Epoch 9/40\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.3345 - val_loss: 0.2234\n",
      "Epoch 10/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.3080 - val_loss: 0.2117\n",
      "Epoch 11/40\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.2963 - val_loss: 0.2085\n",
      "Epoch 12/40\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.2835 - val_loss: 0.1962\n",
      "Epoch 13/40\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.2775 - val_loss: 0.1944\n",
      "Epoch 14/40\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.2757 - val_loss: 0.1933\n",
      "Epoch 15/40\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 0.2750 - val_loss: 0.1958\n",
      "Epoch 16/40\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.2694 - val_loss: 0.1865\n",
      "Epoch 17/40\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.2690 - val_loss: 0.1922\n",
      "Epoch 18/40\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.2641 - val_loss: 0.1884\n",
      "Epoch 19/40\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.2619 - val_loss: 0.1841\n",
      "Epoch 20/40\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.2632 - val_loss: 0.1880\n",
      "Epoch 21/40\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.2576 - val_loss: 0.1925\n",
      "Epoch 22/40\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.2553 - val_loss: 0.1936\n",
      "Epoch 23/40\n",
      "500/500 [==============================] - 54s 109ms/step - loss: 0.2494 - val_loss: 0.1951\n",
      "Epoch 24/40\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.2513 - val_loss: 0.1856\n",
      "Epoch 25/40\n",
      "500/500 [==============================] - 55s 109ms/step - loss: 0.2419 - val_loss: 0.1931\n",
      "Epoch 26/40\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.2417 - val_loss: 0.1996\n",
      "Epoch 27/40\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.2398 - val_loss: 0.1999\n",
      "Epoch 28/40\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.2386 - val_loss: 0.2094\n",
      "Epoch 29/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.2353 - val_loss: 0.1956\n",
      "Epoch 30/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.2351 - val_loss: 0.2096\n",
      "Epoch 31/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.2337 - val_loss: 0.2243\n",
      "Epoch 32/40\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.2300 - val_loss: 0.2203\n",
      "Epoch 33/40\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.2302 - val_loss: 0.2276\n",
      "Epoch 34/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.2192 - val_loss: 0.2319\n",
      "Epoch 35/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.2201 - val_loss: 0.2424\n",
      "Epoch 36/40\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.2160 - val_loss: 0.2360\n",
      "Epoch 37/40\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.2136 - val_loss: 0.2482\n",
      "Epoch 38/40\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.2115 - val_loss: 0.2478\n",
      "Epoch 39/40\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.2096 - val_loss: 0.2452\n",
      "Epoch 40/40\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.2060 - val_loss: 0.2477\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, Input, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "## Model 2\n",
    "clicks = int(lookback/step)\n",
    "a = 2 + 4\n",
    "inputs = Input(shape=(clicks,float_data.shape[-1]))\n",
    "x = layers.GRU(16,dropout=0.2,recurrent_dropout=0.2,input_shape=(clicks,float_data.shape[-1]))(inputs)\n",
    "x = layers.Dense(1)(x)\n",
    "#This is a giant mess of things that allows us to pick the temperature value from 1 day ago out\n",
    "temp = layers.Flatten()(inputs)\n",
    "temp = layers.Reshape((clicks*float_data.shape[-1],1),input_shape=(clicks*float_data.shape[-1],))(temp)\n",
    "temp = layers.Cropping1D(cropping=(a,clicks*float_data.shape[-1]-a-1))(temp)\n",
    "temp = layers.Flatten()(temp)\n",
    "#Skip connection goes here\n",
    "x = layers.add([x,temp])\n",
    "\n",
    "model=Model(inputs=inputs,outputs=x)\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocgxmgoKgoRh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment 2 template.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
