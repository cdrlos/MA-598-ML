{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "5esRoMwG3oW_",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Adversarially trained autoencoder  \n",
    "\n",
    "In part 1, we train an autoencoder using mean-squared-error (mse).  \n",
    "In part 2, we couple the same autoencoder to a discriminator similar to one use for a GAN and train the autoencoder using mse on images plus binary cross entropy on the discriminator loss.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "VZqQalQ83oXA",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We will train our GAN on images from CIFAR10, a dataset of 50,000 32x32 RGB images belong to 10 classes (5,000 images per class). To make \n",
    "things even easier, we will only use images belonging to the class \"frog\".\n",
    "\n",
    "---\n",
    "## Part 1:\n",
    "Schematically, the autoencoder looks like this:\n",
    "\n",
    "* An `encoder` network maps images of shape `(32, 32, 3)` to vectors of shape `(latent_dim,)`.\n",
    "* A `decoder` network maps vectors of shape `(latent_dim,)` to images of shape `(32, 32, 3)`.\n",
    "* An `autoencoder` network chains these together to give `ae_image = decoder(autoencoder(x))`\n",
    "\n",
    "In part 1, this autoencoder is trained to reproduce images, using mse loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "UJk6i9Ge3oXC",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## The autoencoder\n",
    "\n",
    "\n",
    "First,  develop an `autoencoder` model.  \n",
    "* You may use any network structure that you like, **subject to a maximum of 4 million trainable parameters and a latent dimension of 32.   **\n",
    "* It should input a batch of images of shape (32,32,3), funnel down to a batch of vectors 32 dimensional space, and reconstruct back to a batch of images of the same size as the original.  \n",
    "* You may make separate encoder and decoder models and chain them or make a single model.  If you use separate models, you should show the summary for each plus the summary for the full model.\n",
    "\n",
    "Use `autoencoder` as the name of your full model, and use `autoencoder.summary()` to show the structure of your autoencoder.  \n",
    "\n",
    "The final activation should be a sigmoid to provide output values in the range 0 to 1 to create a valid image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "CpKGZzXXGmww",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a655cf2fa68c>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a655cf2fa68c>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    img_output =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "img_input = keras.Input(shape=(height, width, channels))\n",
    "\n",
    "# Your network here to connect img_input to img_output\n",
    "\n",
    "img_output = \n",
    "\n",
    "autoencoder = keras.models.Model(img_input, img_output)\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "uY6biDGR-KGL",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here is some code to load the data and display images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "9nirTlrjtNmc",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Select frog images (class 6)\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "x_test = x_test[y_test.flatten() == 6]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "x_test = x_test.reshape(\n",
    "    (x_test.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# input a tensor of shape (num_images, x_size, y_size, channels)\n",
    "# channels is 1 for greyscale and 3 for color images\n",
    "def show_images(images):\n",
    "  # Display tiled images\n",
    "  n_x = np.int(np.sqrt(images.shape[0]))\n",
    "  n_y = np.int(np.ceil(images.shape[0]/n_x))\n",
    "  tile_x = images.shape[1]\n",
    "  tile_y = images.shape[2]\n",
    "  figure = np.zeros((tile_x * n_x, tile_y * n_y, images.shape[3]))\n",
    "\n",
    "  for i in range(n_x):  \n",
    "    for j in range(n_y):  \n",
    "      cur_ind = i+n_x*j\n",
    "      if (cur_ind >= images.shape[0]):\n",
    "        break\n",
    "      cur_image = images[cur_ind, :,:,:]\n",
    "      figure[i * tile_x: (i + 1) * tile_x,\n",
    "         j * tile_y: (j + 1) * tile_y] = cur_image\n",
    "\n",
    "  plt.figure(figsize=(n_x, n_y))\n",
    "  plt.imshow(np.squeeze(figure))\n",
    "  ax = plt.gca()\n",
    "  ax.grid(b=None)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "ein.tags": "worksheet-0",
    "id": "rHSEMc9iryfB",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Train your autoencoder for 100 epochs and display reconstructed and real images and training history.  ** You should be able to get validation loss below 0.02. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": false,
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "id": "M2HWBIChrxmW",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=num_epochs,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "ae_images = autoencoder.predict(x_train[0:64])\n",
    "show_images(ae_images)\n",
    "show_images(x_train[0:64])\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Adversarially trained autoencoder part 1 template with history.ipynb",
   "provenance": null,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "Adversarially trained autoencoder part 1 template.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
